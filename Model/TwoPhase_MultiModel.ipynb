{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import metrics \n",
    "from tensorflow.keras.layers import Layer,Add, add,AveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D ,Lambda ,GlobalAveragePooling2D,DepthwiseConv2D\n",
    "from tensorflow.keras.layers import concatenate, Add, BatchNormalization, Activation, PReLU, LeakyReLU ,Reshape,Multiply, multiply\n",
    "from tensorflow.keras import regularizers , Input ,Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import ndimage , misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 32\n",
    "QP = \"QP22\"\n",
    "train_dir = \"D:/VCCResearch/\"+QP+\"/dependency_data\"\n",
    "valid_dir = \"D:/VCCResearch/\"+QP+\"/valid_depthall\"\n",
    "#QT_train_dir = \"D:/VCCResearch/\"+QP+\"/dependency_QT78\"\n",
    "TT_train_dir = \"D:/VCCResearch/\"+QP+\"/TT_CU/train_TT\"\n",
    "TT_valid_dir = \"D:/VCCResearch/\"+QP+\"/TT_CU/valid_TT\"\n",
    "\n",
    "QT_train_dir = \"D:/VCCResearch/\"+QP+\"/train_QT_24\"\n",
    "QT_valid_dir = \"D:/VCCResearch/\"+QP+\"/valid_QT_24\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TT OR NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_have_TT_dir = os.path.join(TT_train_dir, 'have_tt')\n",
    "train_no_TT_dir = os.path.join(TT_train_dir, 'no_tt')\n",
    "\n",
    "num_have_TT_tr = len(os.listdir(train_have_TT_dir))\n",
    "num_no_TT_tr = len(os.listdir(train_no_TT_dir))\n",
    "\n",
    "print(\"Have TT: %d\"%num_have_TT_tr)\n",
    "print(\"No TT: %d\"%num_no_TT_tr)\n",
    "\n",
    "total_train_TT = num_have_TT_tr+num_no_TT_tr\n",
    "\n",
    "print(\"===================================================\")\n",
    "\n",
    "print(\"Have TT: %.4f\"%(num_have_TT_tr/total_train_TT))\n",
    "print(\"No TT: %.4f\"%(num_no_TT_tr/total_train_TT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_have_TT_dir = os.path.join(TT_valid_dir, 'have_tt')\n",
    "valid_no_TT_dir = os.path.join(TT_valid_dir, 'no_tt')\n",
    "\n",
    "num_have_TT_val = len(os.listdir(valid_have_TT_dir))\n",
    "num_no_TT_val = len(os.listdir(valid_no_TT_dir))\n",
    "\n",
    "print(\"Have TT: %d\"%num_have_TT_val)\n",
    "print(\"No TT: %d\"%num_no_TT_val)\n",
    "\n",
    "\n",
    "total_valid_TT = num_have_TT_val+num_no_TT_val\n",
    "\n",
    "print(\"===================================================\")\n",
    "\n",
    "print(\"Have TT: %.4f\"%(num_have_TT_val/total_valid_TT))\n",
    "print(\"No TT: %.4f\"%(num_no_TT_val/total_valid_TT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_train_TT)\n",
    "print(total_valid_TT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TT_train_image_generator = ImageDataGenerator(rescale = 1./255)\n",
    "TT_train_data_gen = TT_train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=TT_train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TT_validation_image_generator = ImageDataGenerator(rescale = 1./255)\n",
    "TT_val_data_gen = TT_validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=TT_valid_dir,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              shuffle=False,\n",
    "                                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_QT2_dir = os.path.join(QT_train_dir, 'QT2')\n",
    "train_QT3_dir = os.path.join(QT_train_dir, 'QT3')\n",
    "\n",
    "num_QT2_tr = len(os.listdir(train_QT2_dir))\n",
    "num_QT3_tr = len(os.listdir(train_QT3_dir))\n",
    "\n",
    "\n",
    "\n",
    "print(\"QT2: %d\"%num_QT2_tr)\n",
    "print(\"QT3: %d\"%num_QT3_tr)\n",
    "\n",
    "total_train_QT = num_QT2_tr+num_QT3_tr\n",
    "\n",
    "print(\"===================================================\")\n",
    "\n",
    "print(\"QT2: %.4f\"%(num_QT2_tr/total_train_QT))\n",
    "print(\"QT3: %.4f\"%(num_QT3_tr/total_train_QT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_QT2_dir = os.path.join(QT_valid_dir, 'QT2')\n",
    "valid_QT3_dir = os.path.join(QT_valid_dir, 'QT3')\n",
    "\n",
    "num_QT2_valid = len(os.listdir(valid_QT2_dir))\n",
    "num_QT3_valid = len(os.listdir(valid_QT3_dir))\n",
    "\n",
    "\n",
    "print(\"QT2: %d\"%num_QT2_valid)\n",
    "print(\"QT3: %d\"%num_QT3_valid)\n",
    "\n",
    "total_valid_QT = num_QT2_valid+num_QT3_valid\n",
    "\n",
    "\n",
    "print(\"===================================================\")\n",
    "print(\"QT2: %.4f\"%(num_QT2_valid/total_valid_QT))\n",
    "print(\"QT3: %.4f\"%(num_QT3_valid/total_valid_QT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_train_QT)\n",
    "print(total_valid_QT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QT_train_image_generator = ImageDataGenerator(rescale = 1./255)\n",
    "QT_train_data_gen = QT_train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=QT_train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QT_validation_image_generator = ImageDataGenerator(rescale = 1./255)\n",
    "QT_val_data_gen = QT_validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=QT_valid_dir,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              shuffle=False,\n",
    "                                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QT+BT+TT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_depth5_6_dir = os.path.join(train_dir, 'depth5_6')\n",
    "train_depth7_8_dir = os.path.join(train_dir, 'depth7_8')\n",
    "train_depth9_10_dir = os.path.join(train_dir, 'depth9_10')\n",
    "\n",
    "\n",
    "num_depth5_6_tr = len(os.listdir(train_depth5_6_dir))\n",
    "num_depth7_8_tr = len(os.listdir(train_depth7_8_dir))\n",
    "num_depth9_10_tr = len(os.listdir(train_depth9_10_dir))\n",
    "\n",
    "\n",
    "print(\"depth5_6: %d\"%num_depth5_6_tr)\n",
    "print(\"depth7_8: %d\"%num_depth7_8_tr)\n",
    "print(\"depth9_10: %d\"%num_depth9_10_tr)\n",
    "\n",
    "\n",
    "total_train = num_depth5_6_tr+num_depth7_8_tr+num_depth9_10_tr\n",
    "\n",
    "print(\"===================================================\")\n",
    "\n",
    "print(\"depth5_6: %.3f\"%(num_depth5_6_tr/total_train))\n",
    "print(\"depth7_8: %.3f\"%(num_depth7_8_tr/total_train))\n",
    "print(\"depth9_10: %.3f\"%(num_depth9_10_tr/total_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_depth5_6_dir = os.path.join(valid_dir, 'depth5_6')\n",
    "valid_depth7_8_dir = os.path.join(valid_dir, 'depth7_8')\n",
    "valid_depth9_10_dir = os.path.join(valid_dir, 'depth9_10')\n",
    "\n",
    "\n",
    "num_depth5_6_valid = len(os.listdir(valid_depth5_6_dir))\n",
    "num_depth7_8_valid = len(os.listdir(valid_depth7_8_dir))\n",
    "num_depth9_10_valid = len(os.listdir(valid_depth9_10_dir))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(num_depth5_6_valid)\n",
    "print(num_depth7_8_valid)\n",
    "print(num_depth9_10_valid)\n",
    "\n",
    "\n",
    "\n",
    "total_val = num_depth5_6_valid+num_depth7_8_valid+num_depth9_10_valid\n",
    "\n",
    "print(\"===================================================\")\n",
    "\n",
    "print(\"depth5_6: %.3f\"%(num_depth5_6_valid/total_val))\n",
    "print(\"depth7_8: %.3f\"%(num_depth7_8_valid/total_val))\n",
    "print(\"depth9_10: %.3f\"%(num_depth9_10_valid/total_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_train)\n",
    "print(total_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validation_image_generator = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=valid_dir,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              shuffle=False,\n",
    "                                                              class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_training_images, tr_label = next(train_data_gen)\n",
    "print(sample_training_images.shape)\n",
    "print(tf.image.rgb_to_yuv(sample_training_images[0])[:,:,0:1])\n",
    "print(\"=====\")\n",
    "print(sample_training_images[0][:,:,1])\n",
    "print(\"=====\")\n",
    "print(sample_training_images[0][:,:,2])\n",
    "#print(tf.image.rgb_to_yuv(sample_training_images[0])[:,:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(8, 16, figsize=(32,32))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(sample_training_images[:128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Swish, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        return tf.nn.swish(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNet base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "def swish(x):\n",
    "        \"\"\"Swish activation function: x * sigmoid(x).\n",
    "        Reference: [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n",
    "        \"\"\"\n",
    "\n",
    "        return tf.nn.sigmoid(x) * x\n",
    "\n",
    "def MobileNetv2(input_shape, k, alpha=1.0):\n",
    "\n",
    "    inputs_img = Input(shape=input_shape,name = 'Input0')\n",
    "\n",
    "    first_filters = _make_divisible(16 * alpha, 8)\n",
    "    '''conv0'''\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    x = Conv2D(16, (3,3), padding='same', strides=(1,1),name='conv0')(inputs_img)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN0')(x)\n",
    "    x = Activation(swish)(x) ##16\n",
    "    '''conv0'''\n",
    "    \n",
    "    '''_inverted_residual_block stage1 '''\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 1\n",
    "    # Width\n",
    "    cchannel = int(16 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv1')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN1')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv2')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN2')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv3')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN3')(x)\n",
    "    #x = Add()([x, inputs])\n",
    "    ###################################\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 1\n",
    "    # Width\n",
    "    cchannel = int(16 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv4')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN4')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv5')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN5')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv6')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN6')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    '''_inverted_residual_block stage1'''\n",
    "    \n",
    "    x = Conv2D(16, (2,2), padding='same', strides=(2,2),name='conv7')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN7')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    '''_inverted_residual_block stage2'''\n",
    "    \n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(32 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv8')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN8')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv9')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN9')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv10')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN10')(x)\n",
    "    #x = Add()([x, inputs])\n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(32 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv11')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN11')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv12')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN12')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv13')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN13')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    \n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(32 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv14')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN14')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv15')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN15')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv16')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN16')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    \n",
    "    '''_inverted_residual_block stage2'''\n",
    "    \n",
    "    x = Conv2D(32, (2,2), padding='same', strides=(2,2),name='conv17')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN17')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    '''_inverted_residual_block stage3'''\n",
    "    #1\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(64 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv18')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN18')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv19')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN19')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv20')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN20')(x)\n",
    "    #x = Add()([x, inputs])\n",
    "    \n",
    "    ###################################\n",
    "    #2\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(64 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv21')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN22')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv23')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN23')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv24')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN24')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    #3\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(64 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv25')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN25')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv26')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN26')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv27')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN27')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    #4\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(64 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv28')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN28')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv29')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN29')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv30')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN30')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    \n",
    "#    branch_2 = x\n",
    "    '''_inverted_residual_block stage3'''\n",
    "    \n",
    "    x = Conv2D(64, (2,2), padding='same', strides=(2,2),name='conv31')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN31')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''branch_2'''\n",
    "#     branch_2 = Conv2D(128, (1,1), padding='same', strides=(1,1),name='b2_conv0')(branch_2)\n",
    "#     branch_2 = BatchNormalization(axis=channel_axis,name='b2_BN0')(branch_2)\n",
    "#     branch_2 = Activation(swish)(branch_2)\n",
    "    \n",
    "#     branch_2 = Conv2D(128, (2,2), padding='same', strides=(2,2),name='b2_conv1')(branch_2)\n",
    "#     branch_2 = BatchNormalization(axis=channel_axis,name='b2_BN1')(branch_2)\n",
    "#     branch_2 = Activation(swish)(branch_2)\n",
    "    \n",
    "#     branch_2 = Conv2D(320, (1,1), padding='same', strides=(1,1),name='b2_conv2')(branch_2)\n",
    "#     branch_2 = BatchNormalization(axis=channel_axis,name='b2_BN2')(branch_2)\n",
    "#     branch_2 = Activation(swish)(branch_2)\n",
    "#     branch_2 = GlobalAveragePooling2D()(branch_2)\n",
    "#     branch_2 = Reshape((1, 1, 320))(branch_2)\n",
    "#     branch_2 = Dropout(0.3, name='b2_Dropout')(branch_2)\n",
    "#     branch_2 = Conv2D(2, (1, 1), padding='same',name = 'b2_conv3')(branch_2)\n",
    "#     branch_2 = Activation('softmax', name='b2_softmax')(branch_2)\n",
    "#     b2_output = Reshape((2,))(branch_2)\n",
    "\n",
    "    \n",
    "    '''branch_2'''\n",
    "    \n",
    "    '''_inverted_residual_block stage4'''\n",
    "    #1\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(96 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv32')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN32')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv33')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN33')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv34')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN34')(x)\n",
    "    #x = Add()([x, inputs])\n",
    "    ###################################\n",
    "    #2\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(96 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv35')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN35')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv36')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN36')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv37')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN37')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    \n",
    "    '''_inverted_residual_block stage4'''\n",
    "    \n",
    "    '''Final Stage'''\n",
    "    \n",
    "    if alpha > 1.0:\n",
    "        last_filters = _make_divisible(320 * alpha, 8)\n",
    "    else:\n",
    "        last_filters = 320\n",
    "\n",
    "        \n",
    "    x = Conv2D(320, (1,1), padding='same', strides=(1,1),name='conv38')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN38')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Reshape((1, 1, last_filters))(x)\n",
    "    x = Dropout(0.3, name='Dropout')(x)\n",
    "    x = Conv2D(k, (1, 1), padding='same',name = 'conv39')(x)\n",
    "    x = Activation('softmax', name='softmax')(x)\n",
    "    output = Reshape((k,))(x)\n",
    "\n",
    "    model = Model(inputs_img, output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetv2((32, 32, 3), 3, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_layer_name = []\n",
    "for layer in model.layers[:]:\n",
    "    freeze_layer_name.append(layer.name)\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(freeze_layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNet two branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "def swish(x):\n",
    "        \"\"\"Swish activation function: x * sigmoid(x).\n",
    "        Reference: [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n",
    "        \"\"\"\n",
    "\n",
    "        return tf.nn.sigmoid(x) * x\n",
    "\n",
    "def MobileNetv2(input_shape, k, alpha=1.0):\n",
    "    \n",
    "    inputs_img = Input(shape=input_shape,name = 'Input0')\n",
    "\n",
    "    first_filters = _make_divisible(16 * alpha, 8)\n",
    "    '''conv0'''\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    x = Conv2D(16, (3,3), padding='same', strides=(1,1),name='conv0')(inputs_img)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN0')(x)\n",
    "    x = Activation(swish)(x) ##16\n",
    "    '''conv0'''\n",
    "    \n",
    "    '''_inverted_residual_block stage1 '''\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 1\n",
    "    # Width\n",
    "    cchannel = int(16 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv1')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN1')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv2')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN2')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv3')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN3')(x)\n",
    "    #x = Add()([x, inputs])\n",
    "    ###################################\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 1\n",
    "    # Width\n",
    "    cchannel = int(16 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv4')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN4')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv5')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN5')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv6')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN6')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    '''_inverted_residual_block stage1'''\n",
    "    \n",
    "    x = Conv2D(16, (2,2), padding='same', strides=(2,2),name='conv7')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN7')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    '''_inverted_residual_block stage2'''\n",
    "    \n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(32 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv8')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN8')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv9')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN9')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv10')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN10')(x)\n",
    "    #x = Add()([x, inputs])\n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(32 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv11')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN11')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv12')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN12')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv13')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN13')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    \n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(32 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv14')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN14')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv15')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN15')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv16')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN16')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    \n",
    "    '''_inverted_residual_block stage2'''\n",
    "    \n",
    "    x = Conv2D(32, (2,2), padding='same', strides=(2,2),name='conv17')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN17')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    '''_inverted_residual_block stage3'''\n",
    "    #1\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(64 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv18')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN18')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv19')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN19')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv20')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN20')(x)\n",
    "    #x = Add()([x, inputs])\n",
    "    \n",
    "    ###################################\n",
    "    #2\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(64 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv21')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN22')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv23')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN23')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv24')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN24')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    #3\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(64 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv25')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN25')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv26')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN26')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv27')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN27')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    #4\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(64 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv28')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN28')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv29')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN29')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv30')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN30')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    \n",
    "    branch_tt = x\n",
    "\n",
    "    '''_inverted_residual_block stage3'''\n",
    "    \n",
    "    x = Conv2D(64, (2,2), padding='same', strides=(2,2),name='conv31')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN31')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    \n",
    "    '''bracnch_tt'''\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(branch_tt)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(96 * 1)\n",
    "    branch_tt = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='b5_conv0')(branch_tt)\n",
    "    branch_tt = BatchNormalization(axis=channel_axis,name='b5_BN0')(branch_tt)\n",
    "    branch_tt = Activation(swish)(branch_tt)\n",
    "    \n",
    "    branch_tt = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'b5_conv1')(branch_tt)\n",
    "    branch_tt = BatchNormalization(axis=channel_axis,name = 'b5_BN1')(branch_tt)\n",
    "    branch_tt = Activation(swish)(branch_tt)   \n",
    "    branch_tt = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='b5_conv2')(branch_tt)\n",
    "    branch_tt = BatchNormalization(axis=channel_axis,name = 'b5_BN2')(branch_tt)\n",
    "    \n",
    "    branch_tt = Conv2D(320, (1,1), padding='same', strides=(1,1),name='b5_conv3')(branch_tt)\n",
    "    branch_tt = BatchNormalization(axis=channel_axis,name='b5_BN3')(branch_tt)\n",
    "    branch_tt = Activation(swish)(branch_tt)\n",
    "    branch_tt = GlobalAveragePooling2D()(branch_tt)\n",
    "    branch_tt = Reshape((1, 1, 320))(branch_tt)\n",
    "    branch_tt = Dropout(0.3, name='b5_Dropout')(branch_tt)\n",
    "    branch_tt = Conv2D(2, (1, 1), padding='same',name = 'b5_conv4')(branch_tt)\n",
    "    branch_tt = Activation('softmax', name='b5_softmax')(branch_tt)\n",
    "    b5_output = Reshape((2,))(branch_tt)\n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "\n",
    "    \n",
    "    '''_inverted_residual_block stage4'''\n",
    "    #1\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(96 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv32')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN32')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv33')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN33')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv34')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN34')(x)\n",
    "    #x = Add()([x, inputs])\n",
    "    ###################################\n",
    "    #2\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(96 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv35')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN35')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv36')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN36')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv37')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN37')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    \n",
    "    '''_inverted_residual_block stage4'''\n",
    "    \n",
    "    '''Final Stage'''\n",
    "    \n",
    "    if alpha > 1.0:\n",
    "        last_filters = _make_divisible(320 * alpha, 8)\n",
    "    else:\n",
    "        last_filters = 320\n",
    "\n",
    "        \n",
    "    x = Conv2D(320, (1,1), padding='same', strides=(1,1),name='conv38')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN38')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Reshape((1, 1, last_filters))(x)\n",
    "    x = Dropout(0.3, name='Dropout')(x)\n",
    "    x = Conv2D(k, (1, 1), padding='same',name = 'conv39')(x)\n",
    "    x = Activation('softmax', name='softmax')(x)\n",
    "    output = Reshape((k,))(x)\n",
    "\n",
    "    model = Model(inputs_img, b5_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetv2((32, 32, 3), 3, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:]:\n",
    "    if layer.name in freeze_layer_name:\n",
    "        layer.trainable =  False\n",
    "    else:\n",
    "        print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBNet_B3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "def swish(x):\n",
    "        \"\"\"Swish activation function: x * sigmoid(x).\n",
    "        Reference: [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n",
    "        \"\"\"\n",
    "\n",
    "        return tf.nn.sigmoid(x) * x\n",
    "\n",
    "def MobileNetv2(input_shape, k, alpha=1.0):\n",
    "    \n",
    "    inputs_img = Input(shape=input_shape,name = 'Input0')\n",
    "\n",
    "    first_filters = _make_divisible(16 * alpha, 8)\n",
    "    '''conv0'''\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    x = Conv2D(16, (3,3), padding='same', strides=(1,1),name='conv0')(inputs_img)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN0')(x)\n",
    "    x = Activation(swish)(x) ##16\n",
    "    '''conv0'''\n",
    "    \n",
    "    '''_inverted_residual_block stage1 '''\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 1\n",
    "    # Width\n",
    "    cchannel = int(16 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv1')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN1')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv2')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN2')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv3')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN3')(x)\n",
    "    #x = Add()([x, inputs])\n",
    "    ###################################\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 1\n",
    "    # Width\n",
    "    cchannel = int(16 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv4')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN4')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv5')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN5')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv6')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN6')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    '''_inverted_residual_block stage1'''\n",
    "    \n",
    "    x = Conv2D(16, (2,2), padding='same', strides=(2,2),name='conv7')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN7')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    '''_inverted_residual_block stage2'''\n",
    "    \n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(32 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv8')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN8')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv9')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN9')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv10')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN10')(x)\n",
    "    #x = Add()([x, inputs])\n",
    "    \n",
    "    ###################################\n",
    "    \n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(32 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv11')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN11')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv12')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN12')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv13')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN13')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    \n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(32 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv14')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN14')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv15')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN15')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv16')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN16')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    \n",
    "    '''_inverted_residual_block stage2'''\n",
    "    \n",
    "    x = Conv2D(32, (2,2), padding='same', strides=(2,2),name='conv17')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN17')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    '''_inverted_residual_block stage3'''\n",
    "    #1\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(64 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv18')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN18')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv19')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN19')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv20')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN20')(x)\n",
    "    #x = Add()([x, inputs])\n",
    "    \n",
    "    ###################################\n",
    "    #2\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(64 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv21')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN22')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv23')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN23')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv24')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN24')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    #3\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(64 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv25')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN25')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv26')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN26')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv27')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN27')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    #4\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(64 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv28')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN28')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv29')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN29')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv30')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN30')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    \n",
    "    branch_2 = x\n",
    "    branch_3 = x\n",
    "    branch_4 = x\n",
    "    branch_tt = x\n",
    "    '''_inverted_residual_block stage3'''\n",
    "    \n",
    "    x = Conv2D(64, (2,2), padding='same', strides=(2,2),name='conv31')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN31')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    '''branch_tt'''\n",
    "\n",
    "    \n",
    "    '''branch_2'''\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(branch_2)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(96 * 1)\n",
    "    branch_2 = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='b2_conv0')(branch_2)\n",
    "    branch_2 = BatchNormalization(axis=channel_axis,name='b2_BN0')(branch_2)\n",
    "    branch_2 = Activation(swish)(branch_2)\n",
    "    \n",
    "    branch_2 = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'b2_conv1')(branch_2)\n",
    "    branch_2 = BatchNormalization(axis=channel_axis,name = 'b2_BN1')(branch_2)\n",
    "    branch_2 = Activation(swish)(branch_2)   \n",
    "    branch_2 = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='b2_conv2')(branch_2)\n",
    "    branch_2 = BatchNormalization(axis=channel_axis,name = 'b2_BN2')(branch_2)\n",
    "    \n",
    "    branch_2 = Conv2D(320, (1,1), padding='same', strides=(1,1),name='b2_conv3')(branch_2)\n",
    "    branch_2 = BatchNormalization(axis=channel_axis,name='b2_BN3')(branch_2)\n",
    "    branch_2 = Activation(swish)(branch_2)\n",
    "    branch_2 = GlobalAveragePooling2D()(branch_2)\n",
    "    branch_2 = Reshape((1, 1, 320))(branch_2)\n",
    "    branch_2 = Dropout(0.3, name='b2_Dropout')(branch_2)\n",
    "    branch_2 = Conv2D(2, (1, 1), padding='same',name = 'b2_conv4')(branch_2)\n",
    "    branch_2 = Activation('softmax', name='b2_softmax')(branch_2)\n",
    "    b2_output = Reshape((2,))(branch_2)\n",
    "    '''\n",
    "    branch_2 = Conv2D(128, (1,1), padding='same', strides=(1,1),name='b2_conv0')(branch_2)\n",
    "    branch_2 = BatchNormalization(axis=channel_axis,name='b2_BN0')(branch_2)\n",
    "    branch_2 = Activation(swish)(branch_2)\n",
    "    \n",
    "    branch_2 = Conv2D(128, (2,2), padding='same', strides=(2,2),name='b2_conv1')(branch_2)\n",
    "    branch_2 = BatchNormalization(axis=channel_axis,name='b2_BN1')(branch_2)\n",
    "    branch_2 = Activation(swish)(branch_2)\n",
    "    \n",
    "    branch_2 = Conv2D(320, (1,1), padding='same', strides=(1,1),name='b2_conv2')(branch_2)\n",
    "    branch_2 = BatchNormalization(axis=channel_axis,name='b2_BN2')(branch_2)\n",
    "    branch_2 = Activation(swish)(branch_2)\n",
    "    branch_2 = GlobalAveragePooling2D()(branch_2)\n",
    "    branch_2 = Reshape((1, 1, 320))(branch_2)\n",
    "    branch_2 = Dropout(0.3, name='b2_Dropout')(branch_2)\n",
    "    branch_2 = Conv2D(2, (1, 1), padding='same',name = 'b2_conv3')(branch_2)\n",
    "    branch_2 = Activation('softmax', name='b2_softmax')(branch_2)\n",
    "    b2_output = Reshape((2,))(branch_2)\n",
    "    '''\n",
    "    \n",
    "\n",
    "    \n",
    "    '''branch_2'''\n",
    "\n",
    "\n",
    "    '''branch_3'''\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(branch_3)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(96 * 1)\n",
    "    branch_3 = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='b3_conv0')(branch_3)\n",
    "    branch_3 = BatchNormalization(axis=channel_axis,name='b3_BN0')(branch_3)\n",
    "    branch_3 = Activation(swish)(branch_3)\n",
    "    \n",
    "    branch_3 = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'b3_conv1')(branch_3)\n",
    "    branch_3 = BatchNormalization(axis=channel_axis,name = 'b3_BN1')(branch_3)\n",
    "    branch_3 = Activation(swish)(branch_3)   \n",
    "    branch_3 = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='b3_conv2')(branch_3)\n",
    "    branch_3 = BatchNormalization(axis=channel_axis,name = 'b3_BN2')(branch_3)\n",
    "    \n",
    "    branch_3 = Conv2D(320, (1,1), padding='same', strides=(1,1),name='b3_conv3')(branch_3)\n",
    "    branch_3 = BatchNormalization(axis=channel_axis,name='b3_BN3')(branch_3)\n",
    "    branch_3 = Activation(swish)(branch_3)\n",
    "    branch_3 = GlobalAveragePooling2D()(branch_3)\n",
    "    branch_3 = Reshape((1, 1, 320))(branch_3)\n",
    "    branch_3 = Dropout(0.3, name='b3_Dropout')(branch_3)\n",
    "    branch_3 = Conv2D(2, (1, 1), padding='same',name = 'b3_conv4')(branch_3)\n",
    "    branch_3 = Activation('softmax', name='b3_softmax')(branch_3)\n",
    "    b3_output = Reshape((2,))(branch_3)\n",
    "    '''\n",
    "    branch_3 = Conv2D(128, (1,1), padding='same', strides=(1,1),name='b3_conv0')(branch_3)\n",
    "    branch_3 = BatchNormalization(axis=channel_axis,name='b3_BN0')(branch_3)\n",
    "    branch_3 = Activation(swish)(branch_3)\n",
    "    \n",
    "    branch_3 = Conv2D(128, (2,2), padding='same', strides=(2,2),name='b3_conv1')(branch_3)\n",
    "    branch_3 = BatchNormalization(axis=channel_axis,name='b3_BN1')(branch_3)\n",
    "    branch_3 = Activation(swish)(branch_3)\n",
    "    \n",
    "    branch_3 = Conv2D(320, (1,1), padding='same', strides=(1,1),name='b3_conv2')(branch_3)\n",
    "    branch_3 = BatchNormalization(axis=channel_axis,name='b3_BN2')(branch_3)\n",
    "    branch_3 = Activation(swish)(branch_3)\n",
    "    branch_3 = GlobalAveragePooling2D()(branch_3)\n",
    "    branch_3 = Reshape((1, 1, 320))(branch_3)\n",
    "    branch_3 = Dropout(0.3, name='b3_Dropout')(branch_3)\n",
    "    branch_3 = Conv2D(2, (1, 1), padding='same',name = 'b3_conv3')(branch_3)\n",
    "    branch_3 = Activation('softmax', name='b3_softmax')(branch_3)\n",
    "    b3_output = Reshape((2,))(branch_3)\n",
    "    '''\n",
    "    '''branch_3'''\n",
    "    \n",
    "    '''bracnch4'''\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(96 * 1)\n",
    "    branch_4 = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='b4_conv0')(branch_4)\n",
    "    branch_4 = BatchNormalization(axis=channel_axis,name='b4_BN0')(branch_4)\n",
    "    branch_4 = Activation(swish)(branch_4)\n",
    "    \n",
    "    branch_4 = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'b4_conv1')(branch_4)\n",
    "    branch_4 = BatchNormalization(axis=channel_axis,name = 'b4_BN1')(branch_4)\n",
    "    branch_4 = Activation(swish)(branch_4)   \n",
    "    branch_4 = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='b4_conv2')(branch_4)\n",
    "    branch_4 = BatchNormalization(axis=channel_axis,name = 'b4_BN2')(branch_4)\n",
    "    \n",
    "    branch_4 = Conv2D(320, (1,1), padding='same', strides=(1,1),name='b4_conv3')(branch_4)\n",
    "    branch_4 = BatchNormalization(axis=channel_axis,name='b4_BN3')(branch_4)\n",
    "    branch_4 = Activation(swish)(branch_4)\n",
    "    branch_4 = GlobalAveragePooling2D()(branch_4)\n",
    "    branch_4 = Reshape((1, 1, 320))(branch_4)\n",
    "    branch_4 = Dropout(0.3, name='b4_Dropout')(branch_4)\n",
    "    branch_4 = Conv2D(2, (1, 1), padding='same',name = 'b4_conv4')(branch_4)\n",
    "    branch_4 = Activation('softmax', name='b4_softmax')(branch_4)\n",
    "    b4_output = Reshape((2,))(branch_4)\n",
    "    '''\n",
    "    branch_4 = Conv2D(128, (1,1), padding='same', strides=(1,1),name='b4_conv0')(branch_4)\n",
    "    branch_4 = BatchNormalization(axis=channel_axis,name='b4_BN0')(branch_4)\n",
    "    branch_4 = Activation(swish)(branch_4)\n",
    "    \n",
    "    branch_4 = Conv2D(128, (2,2), padding='same', strides=(2,2),name='b4_conv1')(branch_4)\n",
    "    branch_4 = BatchNormalization(axis=channel_axis,name='b4_BN1')(branch_4)\n",
    "    branch_4 = Activation(swish)(branch_4)\n",
    "    \n",
    "    branch_4 = Conv2D(320, (1,1), padding='same', strides=(1,1),name='b4_conv2')(branch_4)\n",
    "    branch_4 = BatchNormalization(axis=channel_axis,name='b4_BN2')(branch_4)\n",
    "    branch_4 = Activation(swish)(branch_4)\n",
    "    branch_4 = GlobalAveragePooling2D()(branch_4)\n",
    "    branch_4 = Reshape((1, 1, 320))(branch_4)\n",
    "    branch_4 = Dropout(0.3, name='b4_Dropout')(branch_4)\n",
    "    branch_4 = Conv2D(2, (1, 1), padding='same',name = 'b4_conv3')(branch_4)\n",
    "    branch_4 = Activation('softmax', name='b4_softmax')(branch_4)\n",
    "    b4_output = Reshape((2,))(branch_4)\n",
    "    '''\n",
    "    \n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(branch_tt)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(96 * 1)\n",
    "    branch_tt = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='b5_conv0')(branch_tt)\n",
    "    branch_tt = BatchNormalization(axis=channel_axis,name='b5_BN0')(branch_tt)\n",
    "    branch_tt = Activation(swish)(branch_tt)\n",
    "    \n",
    "    branch_tt = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'b5_conv1')(branch_tt)\n",
    "    branch_tt = BatchNormalization(axis=channel_axis,name = 'b5_BN1')(branch_tt)\n",
    "    branch_tt = Activation(swish)(branch_tt)   \n",
    "    branch_tt = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='b5_conv2')(branch_tt)\n",
    "    branch_tt = BatchNormalization(axis=channel_axis,name = 'b5_BN2')(branch_tt)\n",
    "    \n",
    "    branch_tt = Conv2D(320, (1,1), padding='same', strides=(1,1),name='b5_conv3')(branch_tt)\n",
    "    branch_tt = BatchNormalization(axis=channel_axis,name='b5_BN3')(branch_tt)\n",
    "    branch_tt = Activation(swish)(branch_tt)\n",
    "    branch_tt = GlobalAveragePooling2D()(branch_tt)\n",
    "    branch_tt = Reshape((1, 1, 320))(branch_tt)\n",
    "    branch_tt = Dropout(0.3, name='b5_Dropout')(branch_tt)\n",
    "    branch_tt = Conv2D(2, (1, 1), padding='same',name = 'b5_conv4')(branch_tt)\n",
    "    branch_tt = Activation('softmax', name='b5_softmax')(branch_tt)\n",
    "    b5_output = Reshape((2,))(branch_tt)\n",
    "    \n",
    "    '''_inverted_residual_block stage4'''\n",
    "    #1\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(96 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv32')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN32')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv33')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN33')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv34')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN34')(x)\n",
    "    #x = Add()([x, inputs])\n",
    "    ###################################\n",
    "    #2\n",
    "    inputs = x\n",
    "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
    "    # Depth\n",
    "    tchannel = tf.keras.backend.int_shape(x)[channel_axis] * 6\n",
    "    # Width\n",
    "    cchannel = int(96 * 1)\n",
    "    x = Conv2D(tchannel, (1,1), padding='same', strides=(1,1),name='conv35')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN35')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    \n",
    "    x = DepthwiseConv2D((3,3), strides=(1, 1), depth_multiplier=1, padding='same',name = 'conv36')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN36')(x)\n",
    "    x = Activation(swish)(x)   \n",
    "    x = Conv2D(cchannel, (1,1), padding='same', strides=(1,1),name='conv37')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name = 'BN37')(x)\n",
    "    x = Add()([x, inputs])\n",
    "    \n",
    "    '''_inverted_residual_block stage4'''\n",
    "    \n",
    "    '''Final Stage'''\n",
    "    \n",
    "    if alpha > 1.0:\n",
    "        last_filters = _make_divisible(320 * alpha, 8)\n",
    "    else:\n",
    "        last_filters = 320\n",
    "\n",
    "        \n",
    "    x = Conv2D(320, (1,1), padding='same', strides=(1,1),name='conv38')(x)\n",
    "    x = BatchNormalization(axis=channel_axis,name='BN38')(x)\n",
    "    x = Activation(swish)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Reshape((1, 1, last_filters))(x)\n",
    "    x = Dropout(0.3, name='Dropout')(x)\n",
    "    x = Conv2D(k, (1, 1), padding='same',name = 'conv39')(x)\n",
    "    x = Activation('softmax', name='softmax')(x)\n",
    "    output = Reshape((k,))(x)\n",
    "\n",
    "    model = Model(inputs_img,[output,b2_output,b3_output,b4_output,b5_output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetv2((32, 32, 3), 3, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.trainable_variables))\n",
    "for layer in model.layers[:]:\n",
    "    if layer.name in freeze_layer_name:\n",
    "        layer.trainable =  False\n",
    "print(len(model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#sgd = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,patience=3, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam,\n",
    "               loss=\"categorical_crossentropy\",\n",
    "               metrics=['accuracy'])\n",
    "# model.compile(optimizer=Adam,\n",
    "#               loss=[categorical_focal_loss(alpha=.25, gamma=2)],\n",
    "#               metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_path = \"checkpoint_SE/cp.ckpt\"\n",
    "CKP_DIR_SAVE_CALLBACKS = './checkpoint/ckpt_QP22_mobile_tt/best_weight_branch_tt.h5'\n",
    "checkpoint_dir = os.path.dirname(CKP_DIR_SAVE_CALLBACKS)\n",
    "#checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=CKP_DIR_SAVE_CALLBACKS,                                   \n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputgenerator=generate_generator_multiple() \n",
    "#checkpoint_path = \"checkpoint_SE\"\n",
    "checkpoint_path = \"./checkpoint/ckpt_QP22_mobile/best_weight_branch1.h5\"\n",
    "#ckp = tf.train.latest_checkpoint(checkpoint_path)\n",
    "model.load_weights(checkpoint_path,by_name=True) \n",
    "\n",
    "checkpoint_path = \"./checkpoint/ckpt_QP22_mobile_tt/best_weight_branch_tt.h5\"\n",
    "\n",
    "model.load_weights(checkpoint_path,by_name=True) \n",
    "#checkpoint_path = \"ckpt_QP37_mobile_b4/best_weight_branch4.h5\"\n",
    "\n",
    "#model.load_weights(checkpoint_path,by_name=True) \n",
    "#testgenerator=generate_val_multiple()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "history = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    #inputgenerator,\n",
    "    steps_per_epoch=total_train // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    #validation_data = testgenerator,\n",
    "    validation_steps=total_val // batch_size,\n",
    "    callbacks=[cp_callback,reduce_lr],\n",
    ")\n",
    "\n",
    "'''\n",
    "history = model.fit_generator(\n",
    "    TT_train_data_gen,\n",
    "    #inputgenerator,\n",
    "    steps_per_epoch=total_train_TT // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=TT_val_data_gen,\n",
    "    #validation_data = testgenerator,\n",
    "    validation_steps=total_valid_TT // batch_size,\n",
    "    callbacks=[cp_callback,reduce_lr],\n",
    "    \n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import math\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"D:/frame/\"\n",
    "seq_name = \"Johnny\"\n",
    "QP = \"QP37\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_processing(filename,currframe = 0):\n",
    "    f = open(\"D:/frame/\"+filename+\"/\"+seq_name+'%d'%currframe+'.txt', \"r\")\n",
    "    rowlist = []\n",
    "    for line in f:\n",
    "        rowpix = line.split(\" \")\n",
    "        results = [int(i) for i in rowpix[:-1]]\n",
    "        rowlist.append(results)\n",
    "    img = np.asarray(rowlist)\n",
    "    img = img /4\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def frame_processing(filename,currframe = 0):\n",
    "    f = open(\"D:/frame/\"+filename+\"/\"+seq_name+'%d'%currframe+'.txt', \"r\")\n",
    "\n",
    "    rowlist = []\n",
    "    for line in f:\n",
    "        rowpix = line.split(\" \")\n",
    "        results = [int(i) for i in rowpix[:-1]]\n",
    "        rowlist.append(results)\n",
    "    img = np.asarray(rowlist)\n",
    "    img = img /4\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = frame_processing(seq_name,0)\n",
    "yuv_img = Image.fromarray(img.astype('uint8')).convert('YCbCr')\n",
    "\n",
    "print(\"origin frame:\")\n",
    "plt.imshow(yuv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_padding(frame,CTU_size = 128):\n",
    "    width , height = frame.shape[1],frame.shape[0]\n",
    "    #print(width,height)\n",
    "    width_CTU_nums = math.ceil(width/128)\n",
    "    height_CTU_nums = math.ceil(height/128)\n",
    "    pad_frame = np.zeros((height_CTU_nums*128,width_CTU_nums*128))\n",
    "    for x in range(height):\n",
    "        for y in range(width):\n",
    "            pad_frame[x][y] = frame[x][y]\n",
    "    return pad_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yuv_img_padding = frame_padding(img)\n",
    "print(\"padding frame:\")\n",
    "yuv_img_padding = Image.fromarray(yuv_img_padding.astype('uint8')).convert('YCbCr')\n",
    "plt.imshow(yuv_img_padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackBone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_list = [\"RaceHorses\",\n",
    "            \"BQSquare\",\"BlowingBubbles\",\"BasketballPass\",\n",
    "            ]\n",
    "QPList = [\"QP22\",\"QP27\",\"QP32\",\"QP37\"]\n",
    "\n",
    "def gen_range(yuv_img,yuv_img_padding,currframe = 0,index = 0,rd_mataining={}):\n",
    "    org_width,org_height = yuv_img.size\n",
    "    width , height = yuv_img_padding.size\n",
    "    \n",
    "    InFirstCTU = 0\n",
    "    with open(prediction_path+'frame'+str(currframe)+'.txt', 'w') as f:\n",
    "        for blocky in range(0, height, 128):\n",
    "            for blockx in range(0, width, 128):\n",
    "                for beginy in range(blocky, blocky+128, 32):\n",
    "                    for beginx in range(blockx, blockx+128, 32):\n",
    "                        if beginx > org_width or beginx + 32 > org_width or beginy > org_height or beginy + 32 > org_height:\n",
    "                            continue\n",
    "                        val = \"\"\n",
    "                        val += str(beginx)+\" \"+str(beginy)+\" \"+str(beginx+32)+\" \"+str(beginy+32)+\" \"\n",
    "                        item = pred_all[index]\n",
    "                        #print(item)\n",
    "                        #InFirstCTU+=1\n",
    "                        \n",
    "                        for ele in rd_mataining[item]:\n",
    "                            val += str(ele)+\" \"\n",
    "                            \n",
    "\n",
    "                        f.write(\"%s\\n\" % (val))\n",
    "                        index+=1\n",
    "                        InFirstCTU+=1\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for QP in QPList:\n",
    "    for seq_name in seq_list:\n",
    "        pred_all = []\n",
    "        checkpoint_path = \"./checkpoint/ckpt_\"+QP+\"_mobile/best_weight_branch1.h5\"\n",
    "        model.load_weights(checkpoint_path,by_name=True)       \n",
    "        test_path = \"/\"+QP+\"_block\"\n",
    "        idx = 0\n",
    "\n",
    "        for i in range(13):\n",
    "\n",
    "            predict_label = []\n",
    "            test_dir = \"D:/frame/\"+seq_name+test_path+\"/test\"+str(i)\n",
    "            print(test_dir)\n",
    "            test_image_generator = ImageDataGenerator(rescale = 1./255)\n",
    "            test_data_gen = test_image_generator.flow_from_directory(batch_size=1,\n",
    "                                                                          directory=test_dir,\n",
    "                                                                          target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                                          shuffle=False,\n",
    "                                                                          class_mode=None)\n",
    "\n",
    "            prediction=model.predict_generator(test_data_gen,verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "            predict_label=np.argmax(prediction,axis=1)\n",
    "            for label in predict_label:\n",
    "                pred_all.append(label)\n",
    "\n",
    "                \n",
    "        rd_mataining = {0:[2,2,3,0],1:[2,4,4,0],2:[3,4,4,2]} #(5-6,7-8,9-10)\n",
    "        #prediction_path = \"D:/frame/\"+seq_name+\"/Prediction/\"+QP+\"/\"\n",
    "        prediction_path = \"D:/frame/\"+seq_name+\"/re_pred/\"+QP+\"/\"\n",
    "        index = 0\n",
    "        for i in range(13):\n",
    "            img = frame_processing(seq_name,i)\n",
    "            yuv_img = Image.fromarray(img.astype('uint8')).convert('YCbCr')\n",
    "            yuv_img_padding = frame_padding(img)\n",
    "            yuv_img_padding = Image.fromarray(yuv_img_padding.astype('uint8')).convert('YCbCr')\n",
    "            index = gen_range(yuv_img,yuv_img_padding,i,index,rd_mataining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackBone & Three Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_list = [\"Tango2\",\"FoodMarket4\",\"Campfire\",\"CatRobot1\",\"DaylightRoad2\",\"ParkRunning3\",\"MarketPlace\",\"RitualDance\",\n",
    "            \"Cactus\",\"BasketballDrive\",\"BQTerrace\",\"RaceHorsesC\",\"BQMall\",\"PartyScene\",\"BasketballDrill\",\"RaceHorses\",\n",
    "            \"BQSquare\",\"BlowingBubbles\",\"BasketballPass\",\"FourPeople\",\"Johnny\",\"KristenAndSara\"\n",
    "            ]\n",
    "#seq_list = [\"Tango2\"]\n",
    "# seq_list = [\"Cactus\"]\n",
    "QPList = [\"QP37\"]\n",
    "#QPList = [\"QP22\",\"QP27\",\"QP32\",\"QP37\"]\n",
    "\n",
    "def gen_range(yuv_img,yuv_img_padding,currframe = 0,index = 0,rd_mataining={}):\n",
    "    org_width,org_height = yuv_img.size\n",
    "    width , height = yuv_img_padding.size\n",
    "    \n",
    "    InFirstCTU = 0\n",
    "    with open(prediction_path+'frame'+str(currframe)+'.txt', 'w') as f:\n",
    "        for blocky in range(0, height, 128):\n",
    "            for blockx in range(0, width, 128):\n",
    "                for beginy in range(blocky, blocky+128, 32):\n",
    "                    for beginx in range(blockx, blockx+128, 32):\n",
    "                        if beginx > org_width or beginx + 32 > org_width or beginy > org_height or beginy + 32 > org_height:\n",
    "                            continue\n",
    "                        val = \"\"\n",
    "                        val += str(beginx)+\" \"+str(beginy)+\" \"+str(beginx+32)+\" \"+str(beginy+32)+\" \"\n",
    "                        item = pred_all[index]\n",
    "                        #print(item)\n",
    "                        #InFirstCTU+=1\n",
    "                        if index in candidate_idx:\n",
    "\n",
    "                            #print(candidate_idx)\n",
    "                            qtitem = pred_conf_label[index]\n",
    "\n",
    "                            if qtitem == 0:\n",
    "                                pred_all[index] = 3\n",
    "                                #print('in')\n",
    "                                for ele in rd_mataining[3]:\n",
    "                                    val += str(ele)+\" \"\n",
    "\n",
    "                            else:\n",
    "                                pred_all[index] = 4\n",
    "                                for ele in rd_mataining[4]:\n",
    "                                    val += str(ele)+\" \"\n",
    "                        elif index in candidate_idx_mid:\n",
    "\n",
    "                            qtitem = pred_conf_label_mid[index]\n",
    "\n",
    "                            if qtitem == 0:\n",
    "                                pred_all[index] = 5\n",
    "                                #print('in')\n",
    "                                for ele in rd_mataining[5]:\n",
    "                                    val += str(ele)+\" \"\n",
    "                                \n",
    "\n",
    "                            else:\n",
    "                                pred_all[index] = 6\n",
    "                                #print('in')\n",
    "                                for ele in rd_mataining[6]:\n",
    "                                    val += str(ele)+\" \"\n",
    "                                    \n",
    "                        elif index in candidate_idx_QT12:\n",
    "\n",
    "                            qtitem = pred_conf_label_QT12[index]\n",
    "\n",
    "                            if qtitem == 0:\n",
    "                                pred_all[index] = 7\n",
    "                                #print('in')\n",
    "                                for ele in rd_mataining[7]:\n",
    "                                    val += str(ele)+\" \"\n",
    "                                \n",
    "\n",
    "                            else:\n",
    "                                pred_all[index] = 8\n",
    "                                #print('in')\n",
    "                                for ele in rd_mataining[8]:\n",
    "                                    val += str(ele)+\" \"\n",
    "                        else:\n",
    "                            for ele in rd_mataining[item]:\n",
    "                                val += str(ele)+\" \"\n",
    "                        #print(pred_all_tt)\n",
    "                        if pred_all_tt[index] == 0:\n",
    "                            val += \"1\"\n",
    "                        else :\n",
    "                            val += \"0\"\n",
    "                        f.write(\"%s\\n\" % (val))\n",
    "                        index+=1\n",
    "                        InFirstCTU+=1\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for QP in QPList:\n",
    "    for seq_name in seq_list:\n",
    "        pred_all = []\n",
    "        pred_all_tt = []\n",
    "        checkpoint_path = \"./checkpoint/ckpt_\"+QP+\"_mobile/best_weight_branch1.h5\"\n",
    "        model.load_weights(checkpoint_path,by_name=True) \n",
    "        checkpoint_path = \"./checkpoint/ckpt_\"+QP+\"_mobile_b2/best_weight_branch2.h5\"\n",
    "        model.load_weights(checkpoint_path,by_name=True) \n",
    "        checkpoint_path = \"./checkpoint/ckpt_\"+QP+\"_mobile_b3/best_weight_branch3.h5\"\n",
    "        model.load_weights(checkpoint_path,by_name=True) \n",
    "        checkpoint_path = \"./checkpoint/ckpt_\"+QP+\"_mobile_b4/best_weight_branch4.h5\"\n",
    "        model.load_weights(checkpoint_path,by_name=True) \n",
    "        checkpoint_path = \"./checkpoint/ckpt_\"+QP+\"_mobile_tt/best_weight_branch_tt.h5\"\n",
    "        model.load_weights(checkpoint_path,by_name=True) \n",
    "\n",
    "        candidate_idx = []\n",
    "        pred_conf_label = []\n",
    "        candidate_idx_mid = []\n",
    "        pred_conf_label_mid = []\n",
    "        candidate_idx_QT12 = []\n",
    "        pred_conf_label_QT12 = []\n",
    "        Threshold = 0.6\n",
    "        Threshold_QT12 = 0.5\n",
    "        Threshold_QT78 = 0.5\n",
    "        \n",
    "        test_path = \"/\"+QP+\"_block\"\n",
    "        idx = 0\n",
    "        idx_mid = 0\n",
    "        idx_QT12 = 0\n",
    "        for i in range(13):\n",
    "\n",
    "            predict_label = []\n",
    "            test_dir = \"D:/frame/\"+seq_name+test_path+\"/test\"+str(i)\n",
    "            print(test_dir)\n",
    "            test_image_generator = ImageDataGenerator(rescale = 1./255)\n",
    "            test_data_gen = test_image_generator.flow_from_directory(batch_size=1,\n",
    "                                                                          directory=test_dir,\n",
    "                                                                          target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                                          shuffle=False,\n",
    "                                                                          class_mode=None)\n",
    "\n",
    "            prediction,pred_QT,pred_QT_mid,pred_QT12,pred_tt=model.predict_generator(test_data_gen,verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "            predict_label=np.argmax(prediction,axis=1)\n",
    "            ###\n",
    "            predict_label_tt=np.argmax(pred_tt,axis=1)\n",
    "            for label in predict_label_tt:\n",
    "                pred_all_tt.append(label)\n",
    "            #print(pred_all_tt)\n",
    "            ###\n",
    "            for label in predict_label:\n",
    "                pred_all.append(label)\n",
    "\n",
    "            pred_QT_label = np.argmax(pred_QT, axis=1)\n",
    "            pred_QT_mid_label = np.argmax(pred_QT_mid, axis=1)#\n",
    "            pred_QT12_label = np.argmax(pred_QT12, axis=1)#\n",
    "            #print(pred_QT12_label)\n",
    "            ################  Depth910 QT 23 branch  ###############\n",
    "            for label in pred_QT_label:\n",
    "                pred_conf_label.append(label)\n",
    "            for pred in pred_QT[:]:\n",
    "                if(np.amax(pred, axis=0) >= Threshold and pred_all[idx] == 2):\n",
    "                    candidate_idx.append(idx)\n",
    "                idx+=1\n",
    "            ################  Depth78 QT 23 branch  ###############\n",
    "            for label in pred_QT_mid_label:\n",
    "                pred_conf_label_mid.append(label)\n",
    "            for pred in pred_QT_mid[:]:\n",
    "                if(np.amax(pred, axis=0) >= Threshold_QT78 and pred_all[idx_mid] == 1):\n",
    "                    candidate_idx_mid.append(idx_mid)\n",
    "                idx_mid+=1\n",
    "             ################   QT 12 branch  ###############\n",
    "            for label in pred_QT12_label:  \n",
    "                pred_conf_label_QT12.append(label)\n",
    "            for pred in pred_QT12[:]:\n",
    "                if(np.amax(pred, axis=0) >= Threshold_QT12 and pred_all[idx_QT12] == 0):\n",
    "                    candidate_idx_QT12.append(idx_QT12)\n",
    "                idx_QT12+=1\n",
    "                \n",
    "        rd_mataining = {0:[2,2,3,0],1:[2,4,4,0],2:[2,5,4,2],3:[2,5,2,5],4:[3,4,4,2],5:[2,4,2,4],6:[3,2,4,0],7:[2,1,2,1],8:[2,2,3,0]} #(5-6,7-8,9-10)\n",
    "        #prediction_path = \"D:/frame/\"+seq_name+\"/Prediction/\"+QP+\"/\"\n",
    "        prediction_path = \"D:/frame/\"+seq_name+\"/Prediction/\"+QP+\"/\"\n",
    "        index = 0\n",
    "        for i in range(13):\n",
    "            img = frame_processing(seq_name,i)\n",
    "            yuv_img = Image.fromarray(img.astype('uint8')).convert('YCbCr')\n",
    "            yuv_img_padding = frame_padding(img)\n",
    "            yuv_img_padding = Image.fromarray(yuv_img_padding.astype('uint8')).convert('YCbCr')\n",
    "            index = gen_range(yuv_img,yuv_img_padding,i,index,rd_mataining)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
